{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpjUssRKXJB6"
   },
   "source": [
    "# RNN's Hyperparameters Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13OcyabhXJB_"
   },
   "source": [
    "### Setting up variables, library and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Xpi46BAX3dO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Run this cell to mount your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6N5p3MiREQza"
   },
   "outputs": [],
   "source": [
    "def load_data(label):\n",
    "  #label = 'all'\n",
    "  print(\"Loading data with all components\")\n",
    "  names_X = ['X_train_labels_niveladas.csv', 'X_test.csv']\n",
    "  names_y = ['y_train_labels_niveladas.csv', 'y_test.csv']\n",
    "\n",
    "  if label == 'all':\n",
    "    features = ('fx|fy|fz|mx|my|mz')\n",
    "  else:\n",
    "    features = label\n",
    "\n",
    "  X = []\n",
    "  y = []\n",
    "\n",
    "  for dataset in names_X:\n",
    "    dataframe = pd.read_csv(''.join([path,dataset]), index_col=0)\n",
    "    dataframe = dataframe.iloc[:, dataframe.columns.str.contains(features)]\n",
    "    #X.append(np.array(dataframe))\n",
    "    X.append(dataframe)\n",
    "\n",
    "  for dataset in names_y:\n",
    "    dataframe = pd.read_csv(''.join([path,dataset]),index_col=0)\n",
    "    #y.append(np.array(dataframe))\n",
    "    y.append(dataframe)\n",
    "\n",
    "  print('Shape X_train: ', np.shape(X[0]))\n",
    "  print('Shape X_test : ', np.shape(X[1]))\n",
    "  print('Shape y_train: ', np.shape(y[0]))\n",
    "  print('Shape y_test : ', np.shape(y[1]))\n",
    "\n",
    "  #return X_train, X_test, y_train, y_test\n",
    "  return X[0], X[1], y[0], y[1], features # X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZWm6lxNtOc1"
   },
   "outputs": [],
   "source": [
    "def reshape_for_lstm(X_reshape):\n",
    "  print(\"Reshaping for LSTM\")\n",
    "  X_reshape = np.array(X_reshape)\n",
    "  #X_reshape = np.array(X_train)[:,:-1]\n",
    "  number_of_features = parameters.count('|') + 1\n",
    "\n",
    "  shape_input = int(np.shape(X_reshape)[1]/number_of_features)\n",
    "  X_new = np.array([])\n",
    "\n",
    "  for example in X_reshape:\n",
    "    # split data for each component, i.e., [fx, fy, fz]\n",
    "    X = np.split(example, number_of_features)\n",
    "    # reshapes each component for LSTM shape\n",
    "    for i, x in enumerate(X):\n",
    "      X[i] = np.reshape(x, (shape_input, 1))\n",
    "\n",
    "    # concatenate all components with new shape and transpose it to be in (n_experiment, timesteps, components)\n",
    "    X_example = np.concatenate([[x for x in X]])\n",
    "    X_example = np.transpose(X_example)\n",
    "    if X_new.shape == (0,):\n",
    "      X_new = X_example\n",
    "    else:\n",
    "      X_new = np.concatenate((X_new, X_example))\n",
    "\n",
    "  print(\"X_new.shape = \", X_new.shape)\n",
    "  #print(\"new y data shape = \", X_test_full.shape)\n",
    "\n",
    "  return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RTxEXZLkXJCC"
   },
   "outputs": [],
   "source": [
    "## Data path handlers\n",
    "#TRAIN_TEST_SET_PATH = '../../Data/train_test/'\n",
    "path = r'/content/drive/My Drive/USP/Doutorado/Artigos - Escrita/2020 - IROS/Datasets/SMOTe_Nivelado/all_components/'\n",
    "META_DATA_PATH = r'/content/drive/My Drive/USP/Doutorado/Artigos - Escrita/2020 - IROS/Datasets/SMOTe_Nivelado/all_components/glahr_meta/'\n",
    "AUG_SET_PATH = '../../Data/aug_data_all/'\n",
    "MODEL_PATH = r'/content/drive/My Drive/USP/Doutorado/Artigos - Escrita/2020 - IROS/Datasets/SMOTe_Nivelado/all_components/glahr_models/'\n",
    "IMAGES_PATH = r'/content/drive/My Drive/USP/Doutorado/Artigos - Escrita/2020 - IROS/Datasets/SMOTe_Nivelado/all_components/glahr_images/'\n",
    "\n",
    "## Selecting the desired features\n",
    "parameters = 'fx|fy|fz|mx|my|mz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nWq0xY9sXJCP"
   },
   "outputs": [],
   "source": [
    "### Getting data and selecting features\n",
    "#X_train = pd.read_csv(TRAIN_TEST_SET_PATH+'X_train.csv',index_col=0)\n",
    "#y_train = pd.read_csv(TRAIN_TEST_SET_PATH+'y_train.csv',index_col=0)\n",
    "#X_test = pd.read_csv(TRAIN_TEST_SET_PATH+'X_test.csv',index_col=0)\n",
    "#y_test = pd.read_csv(TRAIN_TEST_SET_PATH+'y_test.csv',index_col=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test, features = load_data(parameters)\n",
    "X_train['labels'] = y_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMPwjgMCXJCf"
   },
   "outputs": [],
   "source": [
    "### Creating the validation set\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=27)\n",
    "#for train, val in split.split(X_train, X_train['labels']):\n",
    "for train, val in split.split(X_train, X_train['labels']):\n",
    "    X_train_vl = X_train.iloc[train].copy()\n",
    "    X_val = X_train.iloc[val].copy()\n",
    "    \n",
    "y_train_vl = X_train_vl['labels'].copy()\n",
    "y_val = X_val['labels'].copy()\n",
    "\n",
    "X_train_vl = X_train_vl.iloc[:, ~X_train_vl.columns.str.contains('labels')]\n",
    "X_val = X_val.iloc[:, ~X_val.columns.str.contains('labels')]\n",
    "#X_train = X_train.iloc[:, ~X_train.columns.str.contains('labels')]\n",
    "\n",
    "y_train_vl = np.array(y_train_vl)-1\n",
    "y_val = np.array(y_val)-1\n",
    "y_test = np.array(y_test)-1\n",
    "y_train = np.array(y_train)-1\n",
    "\n",
    "print(\"X_train_vl.shape = \", X_train_vl.shape)\n",
    "print(\"X_val.shape = \", X_val.shape)\n",
    "\n",
    "print(\"y_train_vl.shape = \", y_train_vl.shape)\n",
    "print(\"y_val.shape = \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I8RHwNi4XJCm"
   },
   "outputs": [],
   "source": [
    "### Standardizing the data\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#std_scaler = StandardScaler()\n",
    "\n",
    "#X_train = std_scaler.fit_transform(X_train)\n",
    "#X_test = std_scaler.transform(X_test)\n",
    "#X_train_vl = std_scaler.transform(X_train_vl)\n",
    "#X_val = std_scaler.transform(X_val)\n",
    "\n",
    "# AJUSTAR AQUI\n",
    "X_train = X_train/30\n",
    "X_test = X_test/30\n",
    "X_train_vl = X_train_vl/30\n",
    "X_val = X_val/30\n",
    "print(\"X_train.shape = \", X_train.shape)\n",
    "print(\"X_test.shape = \", X_test.shape)\n",
    "print(\"X_train_vl.shape = \", X_train_vl.shape)\n",
    "print(\"X_val.shape = \", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYKeavrDGpAe"
   },
   "outputs": [],
   "source": [
    "### Reshaping data for LSTM\n",
    "X_train = reshape_for_lstm(np.array(X_train)[:,:-1])\n",
    "X_test = reshape_for_lstm(X_test)\n",
    "X_train_vl = reshape_for_lstm(X_train_vl)\n",
    "X_val = reshape_for_lstm(X_val)\n",
    "\n",
    "print(\"\\n\\n\\nX_train.shape = \", X_train.shape)\n",
    "print(\"X_test.shape = \", X_test.shape)\n",
    "print(\"X_train_vl.shape = \", X_train_vl.shape)\n",
    "print(\"X_val.shape = \", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Liy2NzRfXJCt"
   },
   "source": [
    "### Setting up the rnn model and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9SO3BGkXJCv"
   },
   "outputs": [],
   "source": [
    "### Training a simple rnn to use as reference\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ro4tEEDXJC1"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "### Model sketch\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[1556]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='sparse_categorical_crossentropy'\n",
    "                 ,optimizer=optimizer\n",
    "                 ,metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "mlp_simple = keras.wrappers.scikit_learn.KerasClassifier(build_model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4nfDSpphqQ9"
   },
   "outputs": [],
   "source": [
    "### Model LSTM sketch\n",
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=1556, features=6, output_shape=3, dropout_com=0.0, dropout_rec=0.0):\n",
    "\n",
    "  model = keras.models.Sequential()\n",
    "  # input layer\n",
    "  if n_hidden == 0:\n",
    "    model.add(keras.layers.LSTM(units=n_neurons, input_shape=(input_shape,features), return_sequences=False, dropout=dropout_com))\n",
    "  else:\n",
    "    model.add(keras.layers.LSTM(units=n_neurons, input_shape=(input_shape,features), return_sequences=True, dropout=dropout_com, recurrent_dropout=dropout_rec))\n",
    "    if n_hidden > 1:\n",
    "      for layer in range(n_hidden-1):\n",
    "        model.add(keras.layers.LSTM(units=n_neurons, return_sequences=True, dropout=dropout_com, recurrent_dropout=dropout_rec))\n",
    "      else:\n",
    "        model.add(keras.layers.LSTM(units=n_neurons, return_sequences=False, dropout=dropout_com))\n",
    "\n",
    "  # output layer\n",
    "  model.add(keras.layers.Dense(output_shape, activation='softmax'))\n",
    "  optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "  model.compile(loss='sparse_categorical_crossentropy'\n",
    "                ,optimizer=optimizer\n",
    "                ,metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "  return model\n",
    "\n",
    "lstm_model = keras.wrappers.scikit_learn.KerasClassifier(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bjuTVquXXJC6"
   },
   "outputs": [],
   "source": [
    "### Setting Callbacks\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=15,\n",
    "                                               restore_best_weights=True)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(MODEL_PATH+\"lstm_simple.h5\",\n",
    "                                                save_best_only=True)                                     \n",
    "\n",
    "get_stats = pd.DataFrame([])\n",
    "get_stats.to_csv(META_DATA_PATH+'lstm_error_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DEdzXPfXJDA"
   },
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9smvGW2-XJDB"
   },
   "outputs": [],
   "source": [
    "### Setting parameters range for hyperparameter optimzation\n",
    "### Here we will use random search as the optimization method\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_hidden': np.arange(1,5),\n",
    "    'n_neurons': np.arange(1,32),\n",
    "    'learning_rate': reciprocal(3e-4, 3e-2),\n",
    "    'dropout_com': np.arange(0,6)/10,\n",
    "    'dropout_rec': np.arange(0,6)/10\n",
    "    #'input_shape': [X_train_vl.shape[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XL7ux88TXJDH"
   },
   "outputs": [],
   "source": [
    "### Hyperparameter Optimization\n",
    "rnd_search = RandomizedSearchCV(lstm_model, params, n_iter=10, cv=3, n_jobs=1)\n",
    "print(\"X_train_vl.shape = \", X_train_vl.shape)\n",
    "print(\"y_train_vl.shape = \", y_train_vl.shape)\n",
    "rnd_search.fit(X_train_vl, y_train_vl, epochs=100,\n",
    "               validation_split=0.15,\n",
    "               callbacks=[early_stopping, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8L_0FBGXJDO"
   },
   "outputs": [],
   "source": [
    "### Best validation score\n",
    "rnd_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6mzLADVXJDT"
   },
   "outputs": [],
   "source": [
    "### Best set of hyperparameters\n",
    "best_parameters = pd.DataFrame(rnd_search.best_params_, index=['values'])\n",
    "best_parameters.to_csv(MODEL_PATH+'mlp_simple_bp.csv')\n",
    "\n",
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yU-veC3JXJDa"
   },
   "outputs": [],
   "source": [
    "pd.read_csv(MODEL_PATH+'mlp_simple_bp.csv', usecols=['learning_rate']).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wIeJersXJDf"
   },
   "source": [
    "### Training the reference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eg9sGXc1XJDg"
   },
   "outputs": [],
   "source": [
    "### Selecting and retraining the best model\n",
    "best = rnd_search.best_estimator_.model\n",
    "best.fit(X_train, y_train, epochs=200,\n",
    "         validation_data=(X_test, y_test),\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCoyCnUwXJDm"
   },
   "outputs": [],
   "source": [
    "### Model evaluation in accuracy terms\n",
    "best.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_error_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
